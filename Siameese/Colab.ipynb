{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","private_outputs":true,"mount_file_id":"10Naj40Hq2YV_SRk5d61l2BQ4uh0W0lQG","authorship_tag":"ABX9TyO3uV3kaLSocXLQeqN51JHn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Hc1VNXA9iUAh"},"outputs":[],"source":["#Importing all libraries\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n","from tensorflow.keras.metrics import Precision, Recall\n","import tensorflow as tf"]},{"cell_type":"code","source":["import os\n","import cv2\n","import random\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import uuid"],"metadata":{"id":"jVKYBStVikTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup Paths\n","POS_PATH = os.path.join('/content/drive/MyDrive/siameese/data','/content/drive/MyDrive/siameese/data/anchor')\n","NEG_PATH = os.path.join('/content/drive/MyDrive/siameese/data','/content/drive/MyDrive/siameese/data/negative2')\n","ANC_PATH = os.path.join('/content/drive/MyDrive/siameese/data', '/content/drive/MyDrive/siameese/data/positive')\n","VER_PATH = os.path.join('/content/drive/MyDrive/siameese/application_data', '/content/drive/MyDrive/siameese/application_data/verification_images')\n","INP_PATH = os.path.join('/content/drive/MyDrive/siameese/application_data', '/content/drive/MyDrive/siameese/application_data/input_image')"],"metadata":{"id":"ADSfiBRMipCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.config.list_physical_devices('GPU')"],"metadata":{"id":"S8fjOzTPQpOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)"],"metadata":{"id":"WDes36VHQ-X0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(580)\n","positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(580)\n","negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(580)"],"metadata":{"id":"fdv7RT-QGS50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["positives = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n","negatives = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n","data = positives.concatenate(negatives)"],"metadata":{"id":"LEvi1CU8Gzwd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(file_path):\n","    byte_img = tf.io.read_file(file_path)\n","    img = tf.io.decode_jpeg(byte_img)\n","    img = tf.image.resize(img, (105,105))\n","    img = img / 255.0\n","    return img"],"metadata":{"id":"Uk32Ix5rHZOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_twin(input_img, validation_img, label):\n","    return(preprocess(input_img), preprocess(validation_img), label)\n"],"metadata":{"id":"fljInp0dG2rG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data.map(preprocess_twin)\n","data = data.cache()\n","data = data.shuffle(buffer_size=10000)"],"metadata":{"id":"8mWGehI1G5Ir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = data.take(round(len(data)*0.7))\n","train_data = train_data.batch(16)\n","train_data = train_data.prefetch(8)"],"metadata":{"id":"0uPkNn5eHdaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = data.skip(round(len(data)*0.7))\n","test_data = test_data.take(round(len(data)*0.3))\n","test_data = test_data.batch(16, drop_remainder =True)\n","test_data = test_data.prefetch(8)"],"metadata":{"id":"5XZFcdCGHhvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_embedding():\n","    inp = Input(shape=(105,105,3), name='input_image')\n","\n","    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n","    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n","\n","    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n","    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n","\n","    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n","    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n","\n","    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n","    f1 = Flatten()(c4)\n","    d1 = Dense(4096, activation='sigmoid')(f1)\n","\n","\n","    return Model(inputs=[inp], outputs=[d1], name='embedding')"],"metadata":{"id":"d9gflE6tHlFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding = make_embedding()"],"metadata":{"id":"yUSqVsSYHmCh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding.summary()"],"metadata":{"id":"g-MK3tQKHplL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class L1Dist(Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","\n","    def call(self, input_embedding, validation_embedding):\n","        return tf.math.abs(input_embedding - validation_embedding)"],"metadata":{"id":"a5CIN9j3Hsek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_siamese_model():\n","\n","    # Handle inputs\n","    input_image = Input(name='input_img', shape=(105,105,3))\n","    validation_image = Input(name='validaption_img', shape=(105,105,3))\n","\n","\n","    siamese_layer = L1Dist()\n","    siamese_layer._name = 'distance'\n","    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n","\n","    # Classification Layer\n","    classifier = Dense(1, activation='sigmoid')(distances)\n","\n","    return Model(inputs=[input_image, validation_image], outputs=classifier, name='siamese_network')"],"metadata":{"id":"4__Y8HlyHu-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["siamese_model = make_siamese_model()"],"metadata":{"id":"JvE-mFwVHxJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binary_cross_loss = tf.losses.BinaryCrossentropy()\n","opt = tf.keras.optimizers.Adam(0.0001)"],"metadata":{"id":"jZLYZfT_HzfK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_dir = 'training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n","checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"],"metadata":{"id":"2TbUuA-vH2cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(batch):\n","\n","    # Record all operations\n","    with tf.GradientTape() as tape:\n","        X = batch[:2]\n","        y = batch[2]\n","\n","        yhat = siamese_model(X, training=True)\n","        loss = binary_cross_loss(y, yhat)\n","\n","    # Calculate gradients\n","    grad = tape.gradient(loss, siamese_model.trainable_variables)\n","\n","    # Calculate updated weights and apply to siamese model\n","    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n","\n","    return loss"],"metadata":{"id":"kRhjNbPpIK5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(data, EPOCHS):\n","    # loop through epochs\n","    for epoch in range(1, EPOCHS+1):\n","        print('\\n Epoch {}/{}'.format(epoch,EPOCHS))\n","        progbar = tf.keras.utils.Progbar(len(data))\n","\n","        r = Recall()\n","        p = Precision()\n","\n","        # Loop through each batch\n","        for idx, batch in enumerate(data):\n","            loss = train_step(batch)\n","            yhat = siamese_model.predict(batch[:2], verbose=0)\n","            r.update_state(batch[2], yhat)\n","            p.update_state(batch[2], yhat)\n","            progbar.update(idx+1)\n","        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n","\n","        if epoch % 10 == 0:\n","            checkpoint.save(file_prefix=checkpoint_prefix)"],"metadata":{"id":"OhxRkQjUIMDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 20"],"metadata":{"id":"tfqhAKwzIP2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(train_data, EPOCHS)"],"metadata":{"id":"D4PLMgj6ISj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r = Recall()\n","p = Precision()\n","\n","for test_input, test_val, y_true in test_data.as_numpy_iterator():\n","    yhat = siamese_model.predict([test_input, test_val], verbose=0)\n","    r.update_state(y_true, yhat)\n","    p.update_state(y_true, yhat)\n","\n","print(r.result().numpy(), p.result().numpy())"],"metadata":{"id":"y6ZH0B4UIWpk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.figure(figsize=(10,8))\n","plt.subplot(1,2,1)\n","plt.imshow(test_input[8])\n","plt.subplot(1,2,2)\n","plt.imshow(test_val[8])\n","plt.show()\n","print(y_true[8])"],"metadata":{"id":"oIkv7KjYIYoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["siamese_model.save('/content/drive/MyDrive/siameese/siamesemodel_v2.h5')"],"metadata":{"id":"mpMhI5zwIbAq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/drive/MyDrive/siameese/siamesemodel_v2.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"],"metadata":{"id":"n-_Zi_BCIf0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict([test_input, test_val])"],"metadata":{"id":"P77kItqGIiB0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"jIWJUZejIkRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def verify(model, detection_threshold, verification_threshold):\n","    results = []\n","    for image in os.listdir(os.path.join('application_data', 'verification_images')):\n","        input_img = preprocess(os.path.join('application_data', 'input_image', 'input_image.jpg'))\n","        validation_img = preprocess(os.path.join('application_data', 'verification_images', image))\n","\n","        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n","        results.append(result)\n","\n","    detection = np.sum(np.array(results) > detection_threshold)\n","    verification = detection / len(os.listdir(os.path.join('application_data', 'verification_images')))\n","    verified = verification > verification_threshold\n","\n","    return results, verified"],"metadata":{"id":"m6WZmv3aq9N_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    frame = frame[190:190+250, 230:230+250, :]\n","\n","    cv2.imshow('Verification', frame)\n","\n","    # Verification trigger\n","    if cv2.waitKey(10) & 0xFF == ord('v'):\n","        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n","\n","        results, verified = verify(model, 0.5, 0.5)\n","        print(verified)\n","\n","    if cv2.waitKey(10) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"bW5wkeIIwX0D"},"execution_count":null,"outputs":[]}]}