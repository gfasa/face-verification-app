{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uploaded all data files in ondrive and continue training on Google Colab due to lack of gpu\n",
    "-had to change the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc1VNXA9iUAh"
   },
   "outputs": [],
   "source": [
    "#Importing all libraries\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADSfiBRMipCH"
   },
   "outputs": [],
   "source": [
    "# Setup Paths\n",
    "POS_PATH = os.path.join('/content/drive/MyDrive/siameese/data','/content/drive/MyDrive/siameese/data/anchor')\n",
    "NEG_PATH = os.path.join('/content/drive/MyDrive/siameese/data','/content/drive/MyDrive/siameese/data/negative2')\n",
    "ANC_PATH = os.path.join('/content/drive/MyDrive/siameese/data', '/content/drive/MyDrive/siameese/data/positive')\n",
    "VER_PATH = os.path.join('/content/drive/MyDrive/siameese/application_data', '/content/drive/MyDrive/siameese/application_data/verification_images')\n",
    "INP_PATH = os.path.join('/content/drive/MyDrive/siameese/application_data', '/content/drive/MyDrive/siameese/application_data/input_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8fjOzTPQpOU"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDes36VHQ-X0"
   },
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(cuda_only=False,min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdv7RT-QGS50"
   },
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(580)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(580)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEvi1CU8Gzwd"
   },
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk32Ix5rHZOa"
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (105,105))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fljInp0dG2rG"
   },
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img, label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mWGehI1G5Ir"
   },
   "outputs": [],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uPkNn5eHdaZ"
   },
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*0.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XZFcdCGHhvR"
   },
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16, drop_remainder =True)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9gflE6tHlFr"
   },
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(105,105,3), name='input_image')\n",
    "\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUSqVsSYHmCh"
   },
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-MK3tQKHplL"
   },
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5CIN9j3Hsek"
   },
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4__Y8HlyHu-S"
   },
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "\n",
    "    # Handle inputs\n",
    "    input_image = Input(name='input_img', shape=(105,105,3))\n",
    "    validation_image = Input(name='validaption_img', shape=(105,105,3))\n",
    "\n",
    "\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    # Classification Layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='siamese_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvE-mFwVHxJS"
   },
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZLYZfT_HzfK"
   },
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TbUuA-vH2cd"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRhjNbPpIK5a"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "\n",
    "    # Record all operations\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[:2]\n",
    "        y = batch[2]\n",
    "\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "\n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "\n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhxRkQjUIMDD"
   },
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch,EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "\n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "\n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2], verbose=0)\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat)\n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfqhAKwzIP2V"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4PLMgj6ISj0"
   },
   "outputs": [],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6ZH0B4UIWpk"
   },
   "outputs": [],
   "source": [
    "r = Recall()\n",
    "p = Precision()\n",
    "\n",
    "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
    "    yhat = siamese_model.predict([test_input, test_val], verbose=0)\n",
    "    r.update_state(y_true, yhat)\n",
    "    p.update_state(y_true, yhat)\n",
    "\n",
    "print(r.result().numpy(), p.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oIkv7KjYIYoC"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_input[8])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[8])\n",
    "plt.show()\n",
    "print(y_true[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpMhI5zwIbAq"
   },
   "outputs": [],
   "source": [
    "siamese_model.save('/content/drive/MyDrive/siameese/siamesemodel_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-_Zi_BCIf0P"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/content/drive/MyDrive/siameese/siamesemodel_v2.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P77kItqGIiB0"
   },
   "outputs": [],
   "source": [
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIWJUZejIkRj"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6WZmv3aq9N_"
   },
   "source": [
    "downloaded the model and continue the veryfication on the local environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3uV3kaLSocXLQeqN51JHn",
   "gpuType": "T4",
   "mount_file_id": "10Naj40Hq2YV_SRk5d61l2BQ4uh0W0lQG",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
